{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "469122f0",
   "metadata": {},
   "source": [
    "# Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7ea16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7854b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255,zoom_range=0.2,horizontal_flip=True,vertical_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dccbbbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e83facb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1238 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory(r'E:\\vitExternship\\DataSet\\CNN_Dataset\\Training',target_size=(64,64),\n",
    "                                           class_mode='categorical',batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08d84e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de934dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.6875"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1238/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fff28203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x28f12001520>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b40858b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 326 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test = test_datagen.flow_from_directory(r'E:\\vitExternship\\DataSet\\CNN_Dataset\\Testing',target_size=(64,64),\n",
    "                                           class_mode='categorical',batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71653567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "665d3cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bears': 0, 'crows': 1, 'elephants': 2, 'rats': 3}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c2cc1c",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "09e26e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37de8682",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d22d27da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769b9e6b",
   "metadata": {},
   "source": [
    "# Add Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ea072c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(64,64,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3046961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "43e17b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4b235c",
   "metadata": {},
   "source": [
    "# Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29562cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hidden layer1\n",
    "model.add(Dense(300,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "97cb5794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hidden Layer2\n",
    "model.add(Dense(150,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6afc9be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output layer\n",
    "model.add(Dense(4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f1575a",
   "metadata": {},
   "source": [
    "# Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "12d18d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1d6006",
   "metadata": {},
   "source": [
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "910526d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santh\\AppData\\Local\\Temp/ipykernel_20236/234118701.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(x_train,steps_per_epoch=len(x_train),epochs=10,validation_data=x_test,validation_steps=len(x_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 9s 676ms/step - loss: 2.5928 - accuracy: 0.2601 - val_loss: 1.3115 - val_accuracy: 0.3344\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 7s 575ms/step - loss: 1.3415 - accuracy: 0.3611 - val_loss: 1.1938 - val_accuracy: 0.5245\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 7s 559ms/step - loss: 1.1827 - accuracy: 0.4984 - val_loss: 1.0281 - val_accuracy: 0.6104\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 8s 596ms/step - loss: 0.9951 - accuracy: 0.6163 - val_loss: 0.8219 - val_accuracy: 0.6963\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 8s 585ms/step - loss: 0.8481 - accuracy: 0.6769 - val_loss: 0.6829 - val_accuracy: 0.7853\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 8s 586ms/step - loss: 0.7822 - accuracy: 0.6987 - val_loss: 0.6727 - val_accuracy: 0.7393\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 8s 647ms/step - loss: 0.7414 - accuracy: 0.7213 - val_loss: 0.6055 - val_accuracy: 0.7730\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 8s 593ms/step - loss: 0.7020 - accuracy: 0.7221 - val_loss: 0.6300 - val_accuracy: 0.7853\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 7s 561ms/step - loss: 0.6420 - accuracy: 0.7512 - val_loss: 0.6256 - val_accuracy: 0.7607\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 8s 615ms/step - loss: 0.6056 - accuracy: 0.7754 - val_loss: 0.5274 - val_accuracy: 0.8190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28f120f3700>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,steps_per_epoch=len(x_train),epochs=10,validation_data=x_test,validation_steps=len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d98154",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f479910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('animal.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb0af49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
